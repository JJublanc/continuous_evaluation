{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('gym_dynamic_multi_armed_bandit.envs:basic-v0')\n",
    "env.reset()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_step = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle d’interaction\n",
    "states = []\n",
    "\n",
    "for _ in range(nb_step):\n",
    "    observation, reward, done, info = env.step(randint(0, 1))\n",
    "    states.append(env.latent_state)\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "t=2000\n",
    "ax.plot(range(len(states[:t])), [x/20 for x in states[:t]], color=\"#ff9900\", linestyle=\":\", linewidth=4)\n",
    "# ax.plot(range(len(states[:t])), [(1 - x)/20 for x in states[:t]], color=\"#0097a7\", linestyle=\":\", linewidth=4)\n",
    "ax.set_xlabel(\"Visites\", fontsize=18)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "fig.savefig(\"dynamic_state_graph_option1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "t=2000\n",
    "#ax.plot(range(len(states[:t])), [x/20 for x in states[:t]], color=\"#ff9900\", linestyle=\":\", linewidth=4)\n",
    "ax.plot(range(len(states[:t])), [(1 - x)/20 for x in states[:t]], color=\"#0097a7\", linestyle=\":\", linewidth=4)\n",
    "ax.set_xlabel(\"Visites\", fontsize=18)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "fig.savefig(\"dynamic_state_graph_option2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratégie Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle d’interaction\n",
    "actions_random = []\n",
    "rewards_random = []\n",
    "states_random = []\n",
    "\n",
    "for _ in range(nb_step):\n",
    "    # env.render() # renvoie une sortie vidéo, sans cela on ne renvoie rien\n",
    "    # action = env.action_space.sample() # your agent here (this takes random actions)\n",
    "    action = randint(0, 1)\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    \n",
    "    actions_random.append(action)\n",
    "    rewards_random.append(reward)\n",
    "    states_random.append(env.latent_state)\n",
    "    \n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratégie constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle d’interaction\n",
    "actions_strat_const1 = []\n",
    "rewards_strat_const1 = []\n",
    "states_strat_const1 = []\n",
    "\n",
    "for _ in range(nb_step):\n",
    "        \n",
    "    observation, reward, done, info = env.step(1)\n",
    "    \n",
    "    actions_strat_const1.append(1)\n",
    "    rewards_strat_const1.append(reward)\n",
    "    states_strat_const1.append(env.latent_state)\n",
    "    \n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle d’interaction\n",
    "actions_strat_const0 = []\n",
    "rewards_strat_const0 = []\n",
    "states_strat_const0 = []\n",
    "\n",
    "for _ in range(nb_step):\n",
    "        \n",
    "    observation, reward, done, info = env.step(0)\n",
    "    \n",
    "    actions_strat_const0.append(0)\n",
    "    rewards_strat_const0.append(reward)\n",
    "    states_strat_const0.append(env.latent_state)\n",
    "    \n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratégie optimale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle d’interaction\n",
    "actions_optim = []\n",
    "rewards_optim = []\n",
    "states_optim = []\n",
    "\n",
    "for _ in range(nb_step):\n",
    "    # env.render() # renvoie une sortie vidéo, sans cela on ne renvoie rien\n",
    "    # action = env.action_space.sample() # your agent here (this takes random actions)\n",
    "    #if observation[1] < 250 :\n",
    "    #    action = 1 - int(round(observation[0]))\n",
    "    #else:\n",
    "    #    action = int(round(observation[0]))\n",
    "    action = env.latent_state\n",
    "    \n",
    "    # action = randint(0, 1)\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    \n",
    "    actions_optim.append(action)\n",
    "    rewards_optim.append(reward)\n",
    "    states_optim.append(env.latent_state)\n",
    "    \n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_rewards_by_10(rewards):\n",
    "    rewards_sum_10 = []\n",
    "    for i in range(int(len(rewards)/10)):\n",
    "        rewards_sum_10.append((np.sum(rewards[i*10:(i+1)*10])))\n",
    "    \n",
    "    return rewards_sum_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rl_0 = pd.read_csv(\"./experiments/log/\"\\\n",
    "                           \"worker_0.simple_rl_graph.main_level.main_level.agent_0.csv\")\n",
    "results_rl_1 = pd.read_csv(\"./experiments/log/\"\\\n",
    "                           \"worker_0.simple_rl_graph.main_level.main_level.agent_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "365*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = 730\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(sum_rewards_by_10(rewards_strat_const1)[:t], color=\"#6BB0ff\")\n",
    "plt.plot(results_rl_1[\"Training Reward\"][:t], color=\"#ff5050\")\n",
    "\n",
    "plt.ylabel(\"Nombre de conversions\", fontsize=18)\n",
    "plt.xlabel(\"Temps (en jours)\", fontsize=18)\n",
    "\n",
    "plt.legend([\"Stratégie constante\", \"Stratégie choisie par Deep RL\"], framealpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_comparison(t):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(sum_rewards_by_10(rewards_strat_const1)[:t], color=\"#6BB0ff\")\n",
    "    plt.plot(results_rl_1[\"Training Reward\"][:t], color=\"#ff5050\")\n",
    "\n",
    "    plt.ylabel(\"Revenu additionnel\", fontsize=18)\n",
    "    plt.xlabel(\"Temps (en jours)\", fontsize=18)\n",
    "\n",
    "    revenu_random = round(np.sum(sum_rewards_by_10(rewards_strat_const1)[:t]))\n",
    "    revenu_deep_rl = round(np.sum(results_rl_1[\"Training Reward\"][:t]))\n",
    "    \n",
    "    plt.legend([\"Stratégie constante : {}€\".format(revenu_random), \n",
    "                \"Stratégie choisie par Deep RL : {}€\".format(revenu_deep_rl)], framealpha=1)\n",
    "    plt.savefig(\"comparaison_random_deep_rl_{}_jours.png\".format(t))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [30, 90, 365, 730]:\n",
    "    plot_and_save_comparison(t=i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
